{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":52950}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":7.349446,"end_time":"2025-08-31T22:19:31.037382","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-08-31T22:19:23.687936","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"75284e49-3595-4ff7-b9c6-158b9cb8c7ca","cell_type":"markdown","source":"# Proyecto 2\nAriela Mishaan (22052), Alina Carías (22539), Diego Soto (22737), Ignacio Méndez (22613) y Marcos Díaz","metadata":{}},{"id":"a19a0334","cell_type":"markdown","source":"## Librerias","metadata":{}},{"id":"4e469aba-4334-4ee8-b08a-21ec78d0c608","cell_type":"code","source":"import os\nimport json\nimport gc\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation, PillowWriter\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation, PillowWriter\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation, PillowWriter\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T22:51:22.528202Z","iopub.execute_input":"2025-09-09T22:51:22.529045Z","iopub.status.idle":"2025-09-09T22:51:22.534409Z","shell.execute_reply.started":"2025-09-09T22:51:22.529016Z","shell.execute_reply":"2025-09-09T22:51:22.533628Z"}},"outputs":[],"execution_count":3},{"id":"ab569581","cell_type":"markdown","source":"## Carga de datos","metadata":{}},{"id":"4e6f2f28-f847-42c0-a62c-bf46b42d2e4d","cell_type":"code","source":"\ndef load_data(source):\n    \"\"\"\n    source: ruta .parquet o DataFrame ya cargado.\n    Devuelve DataFrame con 'sequence_id' como columna.\n    \"\"\"\n    if isinstance(source, pd.DataFrame):\n        data = source\n    else:\n        data = pd.read_parquet(source)\n    if 'sequence_id' not in data.columns:\n        data = data.reset_index()\n    return data\n\ndef pick_sequence(data: pd.DataFrame, seq_id=None):\n    \"\"\"\n    Devuelve (seq_id, seq_df) para la secuencia pedida o la primera disponible.\n    \"\"\"\n    if seq_id is None:\n        seq_id = data[\"sequence_id\"].iloc[0]\n    seq = data[data[\"sequence_id\"] == seq_id].reset_index(drop=True)\n    return seq_id, seq\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T22:51:26.730534Z","iopub.execute_input":"2025-09-09T22:51:26.730850Z","iopub.status.idle":"2025-09-09T22:51:26.736920Z","shell.execute_reply.started":"2025-09-09T22:51:26.730819Z","shell.execute_reply":"2025-09-09T22:51:26.735867Z"}},"outputs":[],"execution_count":4},{"id":"62a44ad2-1d5f-4a64-8266-4d3c21a35c29","cell_type":"code","source":"PARQUET_PATH = \"/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet\"\ndata = load_data(PARQUET_PATH)\nSEQ_ID, seq = pick_sequence(data)\nprint(\"Usando SEQ_ID:\", SEQ_ID, \"| Frames:\", len(seq))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T22:51:29.356246Z","iopub.execute_input":"2025-09-09T22:51:29.356646Z","iopub.status.idle":"2025-09-09T22:51:43.685442Z","shell.execute_reply.started":"2025-09-09T22:51:29.356609Z","shell.execute_reply":"2025-09-09T22:51:43.684525Z"}},"outputs":[{"name":"stdout","text":"Usando SEQ_ID: 1975433633 | Frames: 127\n","output_type":"stream"}],"execution_count":5},{"id":"964b8663-54a7-4192-906d-aa8fbe4a2088","cell_type":"markdown","source":"## Preprocesamiento","metadata":{}},{"id":"13865121-e142-4990-8e66-f19eabaa0a39","cell_type":"code","source":"# --- Conexiones Mediapipe ---\nHAND_CONNECTIONS = [\n    (0,1),(1,2),(2,3),(3,4),\n    (0,5),(5,6),(6,7),(7,8),\n    (5,9),(9,10),(10,11),(11,12),\n    (9,13),(13,14),(14,15),(15,16),\n    (13,17),(17,18),(18,19),(19,20),\n    (0,17)\n]\nPOSE_CONNECTIONS = [\n    (11,12),(11,13),(13,15),(12,14),(14,16),\n    (11,23),(12,24),(23,24),(23,25),(24,26)\n]\nFACE_CONNECTIONS = [(33,133),(362,263),(61,291),(0,17),(78,308)]\n\nN_POINTS = {\"right_hand\":21,\"left_hand\":21,\"pose\":33,\"face\":468}\nCONNS = {\"right_hand\":HAND_CONNECTIONS,\"left_hand\":HAND_CONNECTIONS,\n         \"pose\":POSE_CONNECTIONS,\"face\":FACE_CONNECTIONS}\n\nCOLS3 = {\n    \"right_hand\":(\"x_right_hand_\",\"y_right_hand_\",\"z_right_hand_\"),\n    \"left_hand\": (\"x_left_hand_\", \"y_left_hand_\", \"z_left_hand_\"),\n    \"pose\":      (\"x_pose_\",      \"y_pose_\",      \"z_pose_\"),\n    \"face\":      (\"x_face_\",      \"y_face_\",      \"z_face_\"),\n}\nCOLS2 = {\n    \"right_hand\":(\"x_right_hand_\",\"y_right_hand_\"),\n    \"left_hand\": (\"x_left_hand_\", \"y_left_hand_\"),\n    \"pose\":      (\"x_pose_\",\"y_pose_\"),\n    \"face\":      (\"x_face_\",\"y_face_\"),\n}\n\n# --- Extracción ---\ndef extract_landmarks3d(row: pd.Series, part: str):\n    px, py, pz = COLS3[part]; n = N_POINTS[part]\n    xs, ys, zs = [], [], []\n    for i in range(n):\n        xs.append(row.get(f\"{px}{i}\", np.nan))\n        ys.append(row.get(f\"{py}{i}\", np.nan))\n        zs.append(row.get(f\"{pz}{i}\", np.nan))\n    return np.array(xs), np.array(ys), np.array(zs)\n\ndef extract_xy(row: pd.Series, part: str, mirror_x=False):\n    px, py = COLS2[part]; n = N_POINTS[part]\n    xs, ys = [], []\n    for i in range(n):\n        x = row.get(f\"{px}{i}\", np.nan)\n        y = row.get(f\"{py}{i}\", np.nan)\n        if part in (\"right_hand\",\"left_hand\") and mirror_x and np.isfinite(x):\n            x = 1 - x\n        xs.append(x); ys.append(y)\n    return np.array(xs), np.array(ys)\n\n# --- Validación y selección de mano ---\ndef count_valid_xy_row(row: pd.Series, part: str, N=21):\n    xs = np.array([row.get(f\"x_{part}_{i}\", np.nan) for i in range(N)])\n    ys = np.array([row.get(f\"y_{part}_{i}\", np.nan) for i in range(N)])\n    return int((np.isfinite(xs) & np.isfinite(ys)).sum())\n\ndef pick_hand(seq: pd.DataFrame, prefer='auto', min_valid=6):\n    if prefer in ('right_hand','left_hand'):\n        return prefer\n    vr = sum(count_valid_xy_row(seq.iloc[i], \"right_hand\", 21) for i in range(len(seq)))\n    vl = sum(count_valid_xy_row(seq.iloc[i], \"left_hand\", 21)  for i in range(len(seq)))\n    return \"right_hand\" if vr >= vl else \"left_hand\"\n\n# --- Drawing ---\ndef draw_connections_3d(ax, xs, ys, zs, connections, color=\"k\", lw=1):\n    for i,j in connections:\n        if i < len(xs) and j < len(xs):\n            if (np.isfinite(xs[i]) and np.isfinite(ys[i]) and np.isfinite(zs[i]) and\n                np.isfinite(xs[j]) and np.isfinite(ys[j]) and np.isfinite(zs[j])):\n                ax.plot([xs[i],xs[j]],[ys[i],ys[j]],[zs[i],zs[j]], color=color, linewidth=lw)\n\ndef draw_connections_2d(ax, xs, ys, connections, color=\"k\", lw=1):\n    for i,j in connections:\n        if i < len(xs) and j < len(xs):\n            if np.isfinite(xs[i]) and np.isfinite(ys[i]) and np.isfinite(xs[j]) and np.isfinite(ys[j]):\n                ax.plot([xs[i],xs[j]],[ys[i],ys[j]], color=color, linewidth=lw)\n\ndef plot_part_3d(ax, row, part, color, title, axis_bounds=None):\n    xs, ys, zs = extract_landmarks3d(row, part)\n    m = np.isfinite(xs) & np.isfinite(ys) & np.isfinite(zs)\n    if m.any():\n        ax.scatter(xs[m], ys[m], zs[m], c=color, s=20)\n    draw_connections_3d(ax, xs, ys, zs, CONNS[part], color=color, lw=1)\n    ax.set_title(title)\n    if axis_bounds and part in axis_bounds:\n        (xmin,xmax),(ymin,ymax),(zmin,zmax) = axis_bounds[part]\n        ax.set_xlim(xmin,xmax); ax.set_ylim(ymin,ymax); ax.set_zlim(zmin,zmax)\n    else:\n        ax.set_xlim(0,1); ax.set_ylim(0,1); ax.set_zlim(-1,1)\n    ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n\ndef plot_part_2d(ax, row, part, color, title, mirror_x=False):\n    xs, ys = extract_xy(row, part, mirror_x=mirror_x)\n    m = np.isfinite(xs) & np.isfinite(ys)\n    if m.any():\n        ax.scatter(xs[m], ys[m], c=color, s=12)\n    draw_connections_2d(ax, xs, ys, CONNS[part], color=color, lw=1)\n    ax.set_title(title)\n\n# --- Bounds ---\ndef _rng(a):\n    lo, hi = np.nanmin(a), np.nanmax(a)\n    if not np.isfinite(lo) or not np.isfinite(hi) or lo == hi: return (0,1)\n    pad = 0.05*(hi-lo); return (lo-pad, hi+pad)\n\ndef compute_axis_bounds_3d(seq: pd.DataFrame, parts):\n    bounds = {}\n    for part in parts:\n        xs_all, ys_all, zs_all = [], [], []\n        for i in range(len(seq)):\n            xs, ys, zs = extract_landmarks3d(seq.iloc[i], part)\n            xs_all.append(xs); ys_all.append(ys); zs_all.append(zs)\n        xs_all = np.concatenate(xs_all); ys_all = np.concatenate(ys_all); zs_all = np.concatenate(zs_all)\n        m = np.isfinite(xs_all) & np.isfinite(ys_all) & np.isfinite(zs_all)\n        if m.any():\n            bounds[part] = (_rng(xs_all[m]), _rng(ys_all[m]), _rng(zs_all[m]))\n    return bounds\n\ndef compute_axis_bounds_2d(seq: pd.DataFrame, parts, mirror_x=False):\n    bounds = {}\n    for part in parts:\n        xs_all, ys_all = [], []\n        for i in range(len(seq)):\n            xs, ys = extract_xy(seq.iloc[i], part, mirror_x=mirror_x)\n            xs_all.append(xs); ys_all.append(ys)\n        xs_all = np.concatenate(xs_all); ys_all = np.concatenate(ys_all)\n        m = np.isfinite(xs_all) & np.isfinite(ys_all)\n        if m.any():\n            bounds[part] = (_rng(xs_all[m]), _rng(ys_all[m]))\n    return bounds\n\ndef set_limits_2d(ax, bounds, parts_subset, invert_y=False):\n    xs, ys = [], []\n    for p in parts_subset:\n        if p in bounds:\n            (xmin,xmax),(ymin,ymax) = bounds[p]\n            xs += [xmin,xmax]; ys += [ymin,ymax]\n    if xs and ys:\n        ax.set_xlim(min(xs), max(xs)); ax.set_ylim(min(ys), max(ys))\n    else:\n        ax.set_xlim(0,1); ax.set_ylim(0,1)\n    ax.set_aspect('equal', adjustable='box')\n    if invert_y: ax.invert_yaxis()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T22:51:52.941145Z","iopub.execute_input":"2025-09-09T22:51:52.941631Z","iopub.status.idle":"2025-09-09T22:51:52.983621Z","shell.execute_reply.started":"2025-09-09T22:51:52.941603Z","shell.execute_reply":"2025-09-09T22:51:52.982724Z"}},"outputs":[],"execution_count":6},{"id":"4d20d9bb","cell_type":"markdown","source":"## Exploración","metadata":{}},{"id":"183c87fd","cell_type":"code","source":"#dataset_df.head()\ndata.shape, data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T22:52:55.542293Z","iopub.execute_input":"2025-09-09T22:52:55.544468Z","iopub.status.idle":"2025-09-09T22:52:55.591292Z","shell.execute_reply.started":"2025-09-09T22:52:55.544399Z","shell.execute_reply":"2025-09-09T22:52:55.590254Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"((161461, 1631),\n    sequence_id  frame  x_face_0  x_face_1  x_face_2  x_face_3  x_face_4  \\\n 0   1975433633      0  0.578892  0.578482  0.582906  0.572686  0.579030   \n 1   1975433633      1  0.577563  0.578528  0.582916  0.572760  0.579090   \n 2   1975433633      2  0.576181  0.576949  0.581346  0.572293  0.577725   \n 3   1975433633      3  0.575575  0.577569  0.581769  0.572443  0.578289   \n 4   1975433633      4  0.577907  0.577628  0.582295  0.572930  0.578345   \n \n    x_face_5  x_face_6  x_face_7  ...  z_right_hand_11  z_right_hand_12  \\\n 0  0.582115  0.591430  0.498995  ...        -0.253687        -0.291687   \n 1  0.582197  0.591687  0.497613  ...              NaN              NaN   \n 2  0.581191  0.591550  0.497113  ...        -0.233556        -0.267114   \n 3  0.581652  0.591728  0.496759  ...        -0.190909        -0.218471   \n 4  0.581873  0.592467  0.498170  ...              NaN              NaN   \n \n    z_right_hand_13  z_right_hand_14  z_right_hand_15  z_right_hand_16  \\\n 0        -0.123892        -0.195255        -0.249135        -0.284375   \n 1              NaN              NaN              NaN              NaN   \n 2        -0.116145        -0.179053        -0.223861        -0.253004   \n 3        -0.093956        -0.149982        -0.188452        -0.211573   \n 4              NaN              NaN              NaN              NaN   \n \n    z_right_hand_17  z_right_hand_18  z_right_hand_19  z_right_hand_20  \n 0        -0.125050        -0.187797        -0.224827        -0.249662  \n 1              NaN              NaN              NaN              NaN  \n 2        -0.122090        -0.173169        -0.200727        -0.219106  \n 3        -0.102759        -0.147642        -0.168562        -0.180578  \n 4              NaN              NaN              NaN              NaN  \n \n [5 rows x 1631 columns])"},"metadata":{}}],"execution_count":7},{"id":"5a9234ff","cell_type":"markdown","source":"Cada entrada en el train tiene el nombre del archivo (path), el id del archivo (file_id), el id de la sequencia o la oración (sequence_id), el id del participante (participant_id) y la frase que se representa con el lenguaje de señas (phrase). El file_id indica el archivo que tiene la data de los landmarks para cada frase y el sequence_id es el indice unico de una secuencia dentro de cada archivo de landmarks. ","metadata":{}},{"id":"70749af3-5acb-4910-8f94-42acde3ba00a","cell_type":"code","source":"columnas = df.columns.tolist()\nprint(columnas)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1f7d7292-07b8-4349-90d9-ba76c6d589d9","cell_type":"markdown","source":"68 documentos de train landmarks\n* x_face 467 columnas\n* x_left_hand 20 columnas\n* x_pose 32 columnas\n* x_right_hand 20 columnas\n* y_face 467 columnas\n* y_left_hand 20 columnas\n* y_pose 32 columnas\n* y_right_hand 20 columnas\n* z_face 467 columnas\n* z_left_hand 20 columnas\n* z_pose 32 columnas\n* z_right_hand 20 columnas\n","metadata":{}},{"id":"e869d8a8-12ee-46f1-90f2-265d0e5bdcb2","cell_type":"code","source":"print(df.shape)\nprint(df.isna().sum().sum())  # total de NaNs\nprint(df.isna().sum()[df.isna().sum() > 0])  # columnas específicas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T04:19:46.847527Z","iopub.execute_input":"2025-09-09T04:19:46.848429Z","iopub.status.idle":"2025-09-09T04:19:50.009383Z","shell.execute_reply.started":"2025-09-09T04:19:46.848394Z","shell.execute_reply":"2025-09-09T04:19:50.008218Z"}},"outputs":[{"name":"stdout","text":"(161461, 1630)\n0\nSeries([], dtype: int64)\n","output_type":"stream"}],"execution_count":8},{"id":"dc8dde7d-a6f5-4d6a-9f87-d86dfc11370a","cell_type":"code","source":"# ==========================================\n# ASL 3D VIS (auto-selección de parte y filtros NaN)\n# ==========================================\n\n\n# -----------------------------\n# (A) Carga de datos\n# -----------------------------\nUSE_EXISTING_DATAFRAME = 'data' in globals()\n\nif not USE_EXISTING_DATAFRAME:\n    PARQUET_PATH = \"/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet\"  # <-- CAMBIA ESTA RUTA\n    data = pd.read_parquet(PARQUET_PATH)\n\nif 'sequence_id' not in data.columns:\n    data = data.reset_index()\n\n# Selecciona una secuencia (la primera por defecto)\nseq_id = data[\"sequence_id\"].iloc[0]\nseq = data[data[\"sequence_id\"] == seq_id].reset_index(drop=True)\n\n# -----------------------------\n# (B) Conexiones Mediapipe\n# -----------------------------\nHAND_CONNECTIONS = [\n    (0, 1), (1, 2), (2, 3), (3, 4),\n    (0, 5), (5, 6), (6, 7), (7, 8),\n    (5, 9), (9, 10), (10, 11), (11, 12),\n    (9, 13), (13, 14), (14, 15), (15, 16),\n    (13, 17), (17, 18), (18, 19), (19, 20),\n    (0, 17)\n]\nFACE_CONNECTIONS = [\n    (33, 133), (362, 263), (61, 291), (0, 17), (78, 308)\n]\nPOSE_CONNECTIONS = [\n    (11, 12),\n    (11, 13), (13, 15),\n    (12, 14), (14, 16),\n    (11, 23), (12, 24),\n    (23, 24), (23, 25), (24, 26)\n]\nN_POINTS = {\"right_hand\": 21, \"left_hand\": 21, \"pose\": 33, \"face\": 468}\nCONNS = {\"right_hand\": HAND_CONNECTIONS, \"left_hand\": HAND_CONNECTIONS,\n         \"pose\": POSE_CONNECTIONS, \"face\": FACE_CONNECTIONS}\nCOLPREFIXES = {\n    \"right_hand\": (\"x_right_hand_\", \"y_right_hand_\", \"z_right_hand_\"),\n    \"left_hand\":  (\"x_left_hand_\",  \"y_left_hand_\",  \"z_left_hand_\"),\n    \"pose\":       (\"x_pose_\",       \"y_pose_\",       \"z_pose_\"),\n    \"face\":       (\"x_face_\",       \"y_face_\",       \"z_face_\"),\n}\n\n# -----------------------------\n# (C) Funciones utilitarias\n# -----------------------------\ndef extract_landmarks(row: pd.Series, part: str, n_points: int):\n    \"\"\"Devuelve arrays (xs, ys, zs) con NaNs donde falten columnas.\"\"\"\n    xs, ys, zs = [], [], []\n    for i in range(n_points):\n        x_col, y_col, z_col = f\"{COLPREFIXES[part][0]}{i}\", f\"{COLPREFIXES[part][1]}{i}\", f\"{COLPREFIXES[part][2]}{i}\"\n        if (x_col in row) and (y_col in row) and (z_col in row):\n            xs.append(row[x_col]); ys.append(row[y_col]); zs.append(row[z_col])\n        else:\n            xs.append(np.nan); ys.append(np.nan); zs.append(np.nan)\n    return np.array(xs), np.array(ys), np.array(zs)\n\ndef count_valid_in_row(row: pd.Series, part: str) -> int:\n    xs, ys, zs = extract_landmarks(row, part, N_POINTS[part])\n    valid = np.isfinite(xs) & np.isfinite(ys) & np.isfinite(zs)\n    return int(valid.sum())\n\ndef part_total_valid(seq: pd.DataFrame, part: str) -> int:\n    # Rápido: suma de válidos sobre N frames (método vectorizado simple)\n    total = 0\n    for idx in range(len(seq)):\n        total += count_valid_in_row(seq.iloc[idx], part)\n    return total\n\ndef draw_connections(ax, xs, ys, zs, connections, color=\"k\"):\n    for i, j in connections:\n        if i < len(xs) and j < len(xs):\n            if (np.isfinite(xs[i]) and np.isfinite(ys[i]) and np.isfinite(zs[i]) and\n                np.isfinite(xs[j]) and np.isfinite(ys[j]) and np.isfinite(zs[j])):\n                ax.plot([xs[i], xs[j]], [ys[i], ys[j]], [zs[i], zs[j]], color=color, linewidth=1)\n\ndef plot_landmarks_subplot(ax, row, part, color, title, axis_bounds=None):\n    xs, ys, zs = extract_landmarks(row, part, N_POINTS[part])\n    mask = np.isfinite(xs) & np.isfinite(ys) & np.isfinite(zs)\n    if mask.any():\n        ax.scatter(xs[mask], ys[mask], zs[mask], c=color, s=20)\n    draw_connections(ax, xs, ys, zs, CONNS[part], color=color)\n    ax.set_title(title)\n    if axis_bounds and part in axis_bounds:\n        (xmin, xmax), (ymin, ymax), (zmin, zmax) = axis_bounds[part]\n        ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax); ax.set_zlim(zmin, zmax)\n    else:\n        # fallback razonable\n        ax.set_xlim(0, 1); ax.set_ylim(0, 1); ax.set_zlim(-1, 1)\n    ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n\n# --- reemplaza tu compute_axis_bounds por este ---\ndef compute_axis_bounds(seq: pd.DataFrame, parts):\n    \"\"\"\n    Calcula límites de ejes por parte a partir de todos los frames.\n    Omite partes que no tengan columnas o datos finitos.\n    \"\"\"\n    bounds = {}\n    for part in parts:\n        if part not in N_POINTS or part not in COLPREFIXES:\n            continue  # parte desconocida\n        xs_all, ys_all, zs_all = [], [], []\n        for idx in range(len(seq)):\n            xs, ys, zs = extract_landmarks(seq.iloc[idx], part, N_POINTS[part])\n            xs_all.append(xs); ys_all.append(ys); zs_all.append(zs)\n        xs_all = np.concatenate(xs_all) if xs_all else np.array([])\n        ys_all = np.concatenate(ys_all) if ys_all else np.array([])\n        zs_all = np.concatenate(zs_all) if zs_all else np.array([])\n        mask = np.isfinite(xs_all) & np.isfinite(ys_all) & np.isfinite(zs_all)\n        if mask.any():\n            xsel, ysel, zsel = xs_all[mask], ys_all[mask], zs_all[mask]\n            def rng(a):\n                lo, hi = np.nanmin(a), np.nanmax(a)\n                if not np.isfinite(lo) or not np.isfinite(hi) or lo == hi:\n                    return (0, 1)\n                pad = 0.05 * (hi - lo)\n                return (lo - pad, hi + pad)\n            bounds[part] = (rng(xsel), rng(ysel), rng(zsel))\n    return bounds\n\n\n# -----------------------------\n# (D) Diagnóstico y selección automática de parte a filtrar\n# -----------------------------\nparts_consider = [\"left_hand\", \"right_hand\", \"pose\", \"face\"]\ntotals = {p: part_total_valid(seq, p) for p in parts_consider}\nprint(\"Puntos válidos totales por parte en la secuencia:\")\nfor p, t in totals.items():\n    print(f\"  {p:>10}: {t}\")\n\n# Elige la parte con mayor cantidad de puntos válidos\nPART_TO_CHECK = max(totals, key=totals.get)\nprint(f\"\\nParte seleccionada para filtrar: {PART_TO_CHECK}\")\n\n# Umbral relativo (20% de puntos de esa parte), al menos 1\nMIN_VALID_POINTS = max(1, int(0.2 * N_POINTS[PART_TO_CHECK]))\nprint(f\"Umbral min_valid: {MIN_VALID_POINTS} (de {N_POINTS[PART_TO_CHECK]} puntos posibles)\")\n\n# Filtra frames; si ninguno pasa, NO filtra (evita ValueError)\nmask = seq.apply(lambda r: count_valid_in_row(r, PART_TO_CHECK) >= MIN_VALID_POINTS, axis=1)\nif mask.any():\n    seq = seq[mask].reset_index(drop=True)\n    print(f\"Frames tras filtro: {len(seq)}\")\nelse:\n    print(\"Advertencia: ningún frame cumple el umbral; se continuará SIN filtrar.\")\n    # no modificamos 'seq'\n\n# -----------------------------\n# (E) Parámetros de dibujo\n# -----------------------------\nDRAW_FACE = True  # True si quieres dibujar cara también\nFPS = 10\nINTERVAL_MS = int(1000 / FPS)\n\n# Límites de ejes (por datos)\nparts_for_bounds = (\"right_hand\", \"left_hand\", \"pose\") + ((\"face\",) if DRAW_FACE else tuple())\n\n# --- calcular bounds una sola vez ---\naxis_bounds = compute_axis_bounds(seq, parts=parts_for_bounds)\n\n# -----------------------------\n# (F) Animación\n# -----------------------------\nfig = plt.figure(figsize=(16, 12))\nax1 = fig.add_subplot(221, projection=\"3d\")\nax2 = fig.add_subplot(222, projection=\"3d\")\nax3 = fig.add_subplot(223, projection=\"3d\")\nax4 = fig.add_subplot(224, projection=\"3d\")\n\ndef update(frame_idx):\n    row = seq.iloc[frame_idx]\n    for ax in (ax1, ax2, ax3, ax4):\n        ax.cla()\n\n    plot_landmarks_subplot(ax1, row, \"right_hand\", \"red\",   \"Right Hand\", axis_bounds)\n    plot_landmarks_subplot(ax2, row, \"left_hand\",  \"blue\",  \"Left Hand\",  axis_bounds)\n\n    if DRAW_FACE:\n        plot_landmarks_subplot(ax3, row, \"face\",       \"green\",  \"Face\", axis_bounds)\n    else:\n        ax3.set_title(\"Face (omitida)\"); ax3.set_axis_off()\n\n    plot_landmarks_subplot(ax4, row, \"pose\",       \"orange\", \"Pose\", axis_bounds)\n\n    fig.suptitle(f\"Seq {seq_id} · Frame {frame_idx+1}/{len(seq)}\", fontsize=16)\n\nanim = FuncAnimation(fig, update, frames=len(seq), interval=INTERVAL_MS)\n\n# -----------------------------\n# (G) Guardar GIF\n# -----------------------------\nOUTPUT_GIF = \"asl_sequence.gif\"\nanim.save(OUTPUT_GIF, writer=PillowWriter(fps=FPS))\nplt.close()\nprint(f\"GIF guardado: {OUTPUT_GIF}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T15:48:26.483918Z","iopub.execute_input":"2025-09-09T15:48:26.484317Z","iopub.status.idle":"2025-09-09T15:49:08.797899Z","shell.execute_reply.started":"2025-09-09T15:48:26.484285Z","shell.execute_reply":"2025-09-09T15:49:08.796792Z"}},"outputs":[{"name":"stdout","text":"Puntos válidos totales por parte en la secuencia:\n   left_hand: 0\n  right_hand: 441\n        pose: 4191\n        face: 59436\n\nParte seleccionada para filtrar: face\nUmbral min_valid: 93 (de 468 puntos posibles)\nFrames tras filtro: 127\nGIF guardado: asl_sequence.gif\n","output_type":"stream"}],"execution_count":6},{"id":"13b27d0d-7a02-4b1a-b13b-7d52787f24f8","cell_type":"code","source":"# ==========================================\n# ASL 2D GIF (manos + pose; opcional cara) con filtros NaN\n# Basado en tu código 3, pero en 2D (x,y) y sin dependencias extra.\n# ==========================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation, PillowWriter\n\n# -----------------------------\n# (A) Carga de datos\n# -----------------------------\nUSE_EXISTING_DATAFRAME = 'data' in globals()\n\nif not USE_EXISTING_DATAFRAME:\n    PARQUET_PATH = \"/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet\"  # <<-- CAMBIA ESTA RUTA\n    data = pd.read_parquet(PARQUET_PATH)\n\nif 'sequence_id' not in data.columns:\n    data = data.reset_index()\n\n# Selecciona una secuencia (la primera por defecto)\nseq_id = data[\"sequence_id\"].iloc[0]\nseq = data[data[\"sequence_id\"] == seq_id].reset_index(drop=True)\n\n# -----------------------------\n# (B) Conexiones Mediapipe\n# -----------------------------\nHAND_CONNECTIONS = [\n    (0, 1), (1, 2), (2, 3), (3, 4),          # pulgar\n    (0, 5), (5, 6), (6, 7), (7, 8),          # índice\n    (5, 9), (9, 10), (10, 11), (11, 12),     # medio\n    (9, 13), (13, 14), (14, 15), (15, 16),   # anular\n    (13, 17), (17, 18), (18, 19), (19, 20),  # meñique\n    (0, 17)                                  # palma\n]\n\nPOSE_CONNECTIONS = [\n    (11, 12),               # hombros\n    (11, 13), (13, 15),     # brazo izq\n    (12, 14), (14, 16),     # brazo der\n    (11, 23), (12, 24),     # torso\n    (23, 24), (23, 25), (24, 26)  # caderas\n]\n\nFACE_CONNECTIONS = [\n    (33, 133), (362, 263),  # ojos\n    (61, 291), (0, 17),     # contorno\n    (78, 308)               # boca\n]\n\nN_POINTS = {\"right_hand\": 21, \"left_hand\": 21, \"pose\": 33, \"face\": 468}\nCONNS = {\"right_hand\": HAND_CONNECTIONS, \"left_hand\": HAND_CONNECTIONS,\n         \"pose\": POSE_CONNECTIONS, \"face\": FACE_CONNECTIONS}\nCOLPREFIXES = {\n    \"right_hand\": (\"x_right_hand_\", \"y_right_hand_\"),\n    \"left_hand\":  (\"x_left_hand_\",  \"y_left_hand_\"),\n    \"pose\":       (\"x_pose_\",       \"y_pose_\"),\n    \"face\":       (\"x_face_\",       \"y_face_\"),\n}\n\n# -----------------------------\n# (C) Funciones utilitarias (2D)\n# -----------------------------\ndef extract_xy(row: pd.Series, part: str, n_points: int):\n    xs, ys = [], []\n    px, py = COLPREFIXES[part]\n    for i in range(n_points):\n        x_col, y_col = f\"{px}{i}\", f\"{py}{i}\"\n        x = row[x_col] if x_col in row else np.nan\n        y = row[y_col] if y_col in row else np.nan\n        xs.append(x); ys.append(y)\n    return np.array(xs), np.array(ys)\n\ndef count_valid_in_row(row: pd.Series, part: str) -> int:\n    xs, ys = extract_xy(row, part, N_POINTS[part])\n    return int((np.isfinite(xs) & np.isfinite(ys)).sum())\n\ndef draw_connections_2d(ax, xs, ys, connections, color=\"k\", lw=1):\n    for i, j in connections:\n        if i < len(xs) and j < len(xs):\n            if np.isfinite(xs[i]) and np.isfinite(ys[i]) and np.isfinite(xs[j]) and np.isfinite(ys[j]):\n                ax.plot([xs[i], xs[j]], [ys[i], ys[j]], color=color, linewidth=lw)\n\ndef scatter_part_2d(ax, row, part, color, title, axis_bounds=None):\n    xs, ys = extract_xy(row, part, N_POINTS[part])\n    mask = np.isfinite(xs) & np.isfinite(ys)\n    if mask.any():\n        ax.scatter(xs[mask], ys[mask], c=color, s=12)\n    draw_connections_2d(ax, xs, ys, CONNS[part], color=color, lw=1)\n    ax.set_title(title)\n\ndef compute_axis_bounds_2d(seq: pd.DataFrame, parts=(\"right_hand\",\"left_hand\",\"pose\")):\n    bounds = {}\n    for part in parts:\n        if part not in N_POINTS or part not in COLPREFIXES: \n            continue\n        xs_all, ys_all = [], []\n        for i in range(len(seq)):\n            xs, ys = extract_xy(seq.iloc[i], part, N_POINTS[part])\n            xs_all.append(xs); ys_all.append(ys)\n        if not xs_all: \n            continue\n        xs_all = np.concatenate(xs_all); ys_all = np.concatenate(ys_all)\n        mask = np.isfinite(xs_all) & np.isfinite(ys_all)\n        if mask.any():\n            xsel, ysel = xs_all[mask], ys_all[mask]\n            def rng(a):\n                lo, hi = np.nanmin(a), np.nanmax(a)\n                if not np.isfinite(lo) or not np.isfinite(hi) or lo == hi:\n                    return (0, 1)\n                pad = 0.05 * (hi - lo)\n                return (lo - pad, hi + pad)\n            bounds[part] = (rng(xsel), rng(ysel))\n    return bounds\n\n# -----------------------------\n# (D) Filtrado suave de frames\n# -----------------------------\n# Elegimos parte con más válidos para filtrar (p. ej., manos suelen ser ruidosas)\nparts_consider = [\"left_hand\", \"right_hand\", \"pose\"]\ntotals = {p: sum(count_valid_in_row(seq.iloc[i], p) for i in range(len(seq))) for p in parts_consider}\nPART_TO_CHECK = max(totals, key=totals.get)\nMIN_VALID = max(1, int(0.2 * N_POINTS[PART_TO_CHECK]))  # 20% del total\nmask = seq.apply(lambda r: count_valid_in_row(r, PART_TO_CHECK) >= MIN_VALID, axis=1)\nif mask.any():\n    seq = seq[mask].reset_index(drop=True)\n\n# -----------------------------\n# (E) Parámetros de dibujo\n# -----------------------------\nDRAW_FACE = False         # pon True si quieres cara 2D\nFPS = 12\nINTERVAL_MS = int(1000 / FPS)\nparts_for_bounds = (\"right_hand\", \"left_hand\", \"pose\") + ((\"face\",) if DRAW_FACE else tuple())\naxis_bounds = compute_axis_bounds_2d(seq, parts=parts_for_bounds)\n\n# -----------------------------\n# (F) Animación 2D (subplots: RH, LH, Pose, Face/opcional)\n# -----------------------------\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))  # uno para manos, otro para pose/face\nplt.tight_layout()\n\ndef set_limits(ax, parts_subset):\n    # Unimos bounds de varias partes para compartir escalas coherentes\n    xs, ys = [], []\n    for p in parts_subset:\n        if p in axis_bounds:\n            (xmin, xmax), (ymin, ymax) = axis_bounds[p]\n            xs += [xmin, xmax]; ys += [ymin, ymax]\n    if xs and ys:\n        ax.set_xlim(min(xs), max(xs))\n        ax.set_ylim(min(ys), max(ys))\n    else:\n        ax.set_xlim(0, 1); ax.set_ylim(0, 1)\n    ax.set_aspect('equal', adjustable='box')\n    # Opcional: invertir Y si tus coords son imagen (origen arriba-izquierda)\n    ax.invert_yaxis()\n\ndef update(frame_idx):\n    row = seq.iloc[frame_idx]\n    ax1.cla(); ax2.cla()\n\n    # Manos en ax1\n    scatter_part_2d(ax1, row, \"right_hand\", \"tab:red\",  \"Right Hand\")\n    scatter_part_2d(ax1, row, \"left_hand\",  \"tab:blue\", \"Left Hand\")\n    set_limits(ax1, (\"right_hand\", \"left_hand\"))\n\n    # Pose (y cara opcional) en ax2\n    scatter_part_2d(ax2, row, \"pose\", \"tab:orange\", \"Pose\")\n    if DRAW_FACE:\n        scatter_part_2d(ax2, row, \"face\", \"tab:green\", \"Face\")\n        set_limits(ax2, (\"pose\", \"face\"))\n    else:\n        set_limits(ax2, (\"pose\",))\n    fig.suptitle(f\"Seq {seq_id} · Frame {frame_idx+1}/{len(seq)}\", fontsize=14)\n\nanim = FuncAnimation(fig, update, frames=len(seq), interval=INTERVAL_MS)\n\n# -----------------------------\n# (G) Guardar GIF\n# -----------------------------\nOUTPUT_GIF = \"asl_2d.gif\"\nanim.save(OUTPUT_GIF, writer=PillowWriter(fps=FPS))\nplt.close()\nprint(f\"GIF 2D guardado: {OUTPUT_GIF}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T16:04:37.115001Z","iopub.execute_input":"2025-09-09T16:04:37.115377Z","iopub.status.idle":"2025-09-09T16:05:26.825428Z","shell.execute_reply.started":"2025-09-09T16:04:37.115351Z","shell.execute_reply":"2025-09-09T16:05:26.824212Z"}},"outputs":[{"name":"stdout","text":"GIF 2D guardado: asl_2d.gif\n","output_type":"stream"}],"execution_count":9},{"id":"a82cf998-a5ee-450c-bc20-31b50d30c01b","cell_type":"code","source":"# ==========================================\n# ASL 3D GIF — mano única (auto/forzada) + pose (opcional cara)\n# ==========================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation, PillowWriter\n\n# -----------------------------\n# (A) Carga de datos y secuencia\n# -----------------------------\nUSE_EXISTING_DATAFRAME = 'data' in globals()\n\nif not USE_EXISTING_DATAFRAME:\n    PARQUET_PATH = \"/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet\"  # <<-- CAMBIA ESTA RUTA\n    data = pd.read_parquet(PARQUET_PATH)\n\nif 'sequence_id' not in data.columns:\n    data = data.reset_index()\n\n# Usa SEQ_ID global si ya lo definiste en otro script; si no, toma el primero\nSEQ_ID = globals().get('SEQ_ID', data[\"sequence_id\"].iloc[0])\nseq = data[data[\"sequence_id\"] == SEQ_ID].reset_index(drop=True)\nprint(\"Usando SEQ_ID =\", SEQ_ID, \"con\", len(seq), \"frames\")\n\n# -----------------------------\n# (B) Conexiones Mediapipe\n# -----------------------------\nHAND_CONNECTIONS = [\n    (0, 1), (1, 2), (2, 3), (3, 4),\n    (0, 5), (5, 6), (6, 7), (7, 8),\n    (5, 9), (9, 10), (10, 11), (11, 12),\n    (9, 13), (13, 14), (14, 15), (15, 16),\n    (13, 17), (17, 18), (18, 19), (19, 20),\n    (0, 17)\n]\nPOSE_CONNECTIONS = [\n    (11, 12),\n    (11, 13), (13, 15),\n    (12, 14), (14, 16),\n    (11, 23), (12, 24),\n    (23, 24), (23, 25), (24, 26)\n]\nFACE_CONNECTIONS = [\n    (33, 133), (362, 263), (61, 291), (0, 17), (78, 308)\n]\n\nN_POINTS = {\"right_hand\": 21, \"left_hand\": 21, \"pose\": 33, \"face\": 468}\nCONNS = {\"right_hand\": HAND_CONNECTIONS, \"left_hand\": HAND_CONNECTIONS,\n         \"pose\": POSE_CONNECTIONS, \"face\": FACE_CONNECTIONS}\nCOLS3 = {\n    \"right_hand\": (\"x_right_hand_\", \"y_right_hand_\", \"z_right_hand_\"),\n    \"left_hand\":  (\"x_left_hand_\",  \"y_left_hand_\",  \"z_left_hand_\"),\n    \"pose\":       (\"x_pose_\",       \"y_pose_\",       \"z_pose_\"),\n    \"face\":       (\"x_face_\",       \"y_face_\",       \"z_face_\"),\n}\n\n# -----------------------------\n# (C) Mano presente: auto/forzada\n# -----------------------------\ndef count_valid_xy_row(row, part, N=21):\n    xs = np.array([row.get(f\"x_{part}_{i}\", np.nan) for i in range(N)])\n    ys = np.array([row.get(f\"y_{part}_{i}\", np.nan) for i in range(N)])\n    return int((np.isfinite(xs) & np.isfinite(ys)).sum())\n\ndef pick_hand(seq, prefer='auto', min_valid=6):\n    if prefer in ('right_hand','left_hand'):\n        return prefer\n    vr = sum(count_valid_xy_row(seq.iloc[i], \"right_hand\", 21) for i in range(len(seq)))\n    vl = sum(count_valid_xy_row(seq.iloc[i], \"left_hand\", 21)  for i in range(len(seq)))\n    return \"right_hand\" if vr >= vl else \"left_hand\"\n\n# Forzar: 'right_hand' | 'left_hand' | 'auto'\nHAND_TO_PLOT = pick_hand(seq, prefer='auto')\nprint(\"Hand seleccionada (3D):\", HAND_TO_PLOT)\n\n# -----------------------------\n# (D) Helpers 3D\n# -----------------------------\ndef extract_landmarks(row: pd.Series, part: str, n_points: int):\n    px, py, pz = COLS3[part]\n    xs, ys, zs = [], [], []\n    for i in range(n_points):\n        x = row.get(f\"{px}{i}\", np.nan)\n        y = row.get(f\"{py}{i}\", np.nan)\n        z = row.get(f\"{pz}{i}\", np.nan)\n        xs.append(x); ys.append(y); zs.append(z)\n    return np.array(xs), np.array(ys), np.array(zs)\n\ndef draw_connections(ax, xs, ys, zs, connections, color=\"k\", lw=1):\n    for i, j in connections:\n        if i < len(xs) and j < len(xs):\n            if (np.isfinite(xs[i]) and np.isfinite(ys[i]) and np.isfinite(zs[i]) and\n                np.isfinite(xs[j]) and np.isfinite(ys[j]) and np.isfinite(zs[j])):\n                ax.plot([xs[i], xs[j]], [ys[i], ys[j]], [zs[i], zs[j]], color=color, linewidth=lw)\n\ndef plot_part_3d(ax, row, part, color, title):\n    xs, ys, zs = extract_landmarks(row, part, N_POINTS[part])\n    mask = np.isfinite(xs) & np.isfinite(ys) & np.isfinite(zs)\n    if mask.any():\n        ax.scatter(xs[mask], ys[mask], zs[mask], c=color, s=20)\n    draw_connections(ax, xs, ys, zs, CONNS[part], color=color, lw=1)\n    ax.set_title(title)\n    ax.set_xlim(0,1); ax.set_ylim(0,1); ax.set_zlim(-1,1)\n    ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n\n# -----------------------------\n# (E) Animación\n# -----------------------------\nDRAW_FACE = True\nFPS = 10\nINTERVAL_MS = int(1000 / FPS)\n\nfig = plt.figure(figsize=(12, 10))\nax_hand = fig.add_subplot(221, projection=\"3d\")\nax_pose = fig.add_subplot(222, projection=\"3d\")\nax_face = fig.add_subplot(223, projection=\"3d\")\n\ndef update(frame_idx):\n    row = seq.iloc[frame_idx]\n    ax_hand.cla(); ax_pose.cla(); ax_face.cla()\n\n    color = \"red\" if HAND_TO_PLOT == \"right_hand\" else \"blue\"\n    title = \"Right Hand\" if HAND_TO_PLOT == \"right_hand\" else \"Left Hand\"\n    plot_part_3d(ax_hand, row, HAND_TO_PLOT, color, title)\n\n    plot_part_3d(ax_pose, row, \"pose\", \"orange\", \"Pose\")\n\n    if DRAW_FACE:\n        plot_part_3d(ax_face, row, \"face\", \"green\", \"Face\")\n    else:\n        ax_face.set_title(\"Face (omitida)\")\n        ax_face.set_axis_off()\n\n    fig.suptitle(f\"Seq {SEQ_ID} · Frame {frame_idx+1}/{len(seq)}\", fontsize=14)\n\nanim = FuncAnimation(fig, update, frames=len(seq), interval=INTERVAL_MS)\n\nOUTPUT_GIF = \"asl_3d.gif\"\nanim.save(OUTPUT_GIF, writer=PillowWriter(fps=FPS))\nplt.close()\nprint(f\"GIF 3D guardado: {OUTPUT_GIF}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T16:15:47.078030Z","iopub.execute_input":"2025-09-09T16:15:47.078504Z","iopub.status.idle":"2025-09-09T16:16:23.088354Z","shell.execute_reply.started":"2025-09-09T16:15:47.078473Z","shell.execute_reply":"2025-09-09T16:16:23.087110Z"}},"outputs":[{"name":"stdout","text":"Usando SEQ_ID = 1975433633 con 127 frames\nHand seleccionada (3D): right_hand\nGIF 3D guardado: asl_3d.gif\n","output_type":"stream"}],"execution_count":12},{"id":"279f217d-8686-4e18-98a8-1f4d467dec65","cell_type":"code","source":"# ==========================================\n# ASL 2D GIF — misma mano que 3D + pose (opcional cara), con MIRROR_X\n# ==========================================\n\n\n# -----------------------------\n# (A) Carga y misma secuencia\n# -----------------------------\nUSE_EXISTING_DATAFRAME = 'data' in globals()\n\nif not USE_EXISTING_DATAFRAME:\n    PARQUET_PATH = \"/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet\"  # <<-- CAMBIA ESTA RUTA\n    data = pd.read_parquet(PARQUET_PATH)\n\nif 'sequence_id' not in data.columns:\n    data = data.reset_index()\n\n# Usa el mismo SEQ_ID si ya existe (del script 3D)\nSEQ_ID = globals().get('SEQ_ID', data[\"sequence_id\"].iloc[0])\nseq = data[data[\"sequence_id\"] == SEQ_ID].reset_index(drop=True)\nprint(\"Usando SEQ_ID =\", SEQ_ID, \"con\", len(seq), \"frames\")\n\n# Usa la misma mano si ya fue calculada; si no, se elige automáticamente\ndef count_valid_xy_row(row, part, N=21):\n    xs = np.array([row.get(f\"x_{part}_{i}\", np.nan) for i in range(N)])\n    ys = np.array([row.get(f\"y_{part}_{i}\", np.nan) for i in range(N)])\n    return int((np.isfinite(xs) & np.isfinite(ys)).sum())\n\ndef pick_hand(seq, prefer='auto', min_valid=6):\n    if prefer in ('right_hand','left_hand'):\n        return prefer\n    vr = sum(count_valid_xy_row(seq.iloc[i], \"right_hand\", 21) for i in range(len(seq)))\n    vl = sum(count_valid_xy_row(seq.iloc[i], \"left_hand\", 21)  for i in range(len(seq)))\n    return \"right_hand\" if vr >= vl else \"left_hand\"\n\nHAND_TO_PLOT = globals().get('HAND_TO_PLOT', pick_hand(seq, prefer='auto'))\nprint(\"Hand seleccionada (2D):\", HAND_TO_PLOT)\n\n# -----------------------------\n# (B) Conexiones y columnas 2D\n# -----------------------------\nHAND_CONNECTIONS = [\n    (0, 1), (1, 2), (2, 3), (3, 4),\n    (0, 5), (5, 6), (6, 7), (7, 8),\n    (5, 9), (9, 10), (10, 11), (11, 12),\n    (9, 13), (13, 14), (14, 15), (15, 16),\n    (13, 17), (17, 18), (18, 19), (19, 20),\n    (0, 17)\n]\nPOSE_CONNECTIONS = [\n    (11, 12),\n    (11, 13), (13, 15),\n    (12, 14), (14, 16),\n    (11, 23), (12, 24),\n    (23, 24), (23, 25), (24, 26)\n]\nFACE_CONNECTIONS = [\n    (33, 133), (362, 263), (61, 291), (0, 17), (78, 308)\n]\n\nN_POINTS = {\"right_hand\": 21, \"left_hand\": 21, \"pose\": 33, \"face\": 468}\nCONNS = {\"right_hand\": HAND_CONNECTIONS, \"left_hand\": HAND_CONNECTIONS,\n         \"pose\": POSE_CONNECTIONS, \"face\": FACE_CONNECTIONS}\nCOLS2 = {\n    \"right_hand\": (\"x_right_hand_\", \"y_right_hand_\"),\n    \"left_hand\":  (\"x_left_hand_\",  \"y_left_hand_\"),\n    \"pose\":       (\"x_pose_\",       \"y_pose_\"),\n    \"face\":       (\"x_face_\",       \"y_face_\"),\n}\n\n# -----------------------------\n# (C) Flags: espejo y cara\n# -----------------------------\nMIRROR_X = False     # True para reflejar mano en X (x -> 1-x) y que “caiga” del mismo lado visual\nDRAW_FACE = False\n\n# -----------------------------\n# (D) Helpers 2D\n# -----------------------------\ndef extract_xy(row: pd.Series, part: str, n_points: int):\n    px, py = COLS2[part]\n    xs, ys = [], []\n    for i in range(n_points):\n        x = row.get(f\"{px}{i}\", np.nan)\n        y = row.get(f\"{py}{i}\", np.nan)\n        if part in (\"right_hand\",\"left_hand\") and MIRROR_X and np.isfinite(x):\n            x = 1 - x\n        xs.append(x); ys.append(y)\n    return np.array(xs), np.array(ys)\n\ndef draw_connections_2d(ax, xs, ys, connections, color=\"k\", lw=1):\n    for i, j in connections:\n        if i < len(xs) and j < len(xs):\n            if np.isfinite(xs[i]) and np.isfinite(ys[i]) and np.isfinite(xs[j]) and np.isfinite(ys[j]):\n                ax.plot([xs[i], xs[j]], [ys[i], ys[j]], color=color, linewidth=lw)\n\ndef plot_part_2d(ax, row, part, color, title):\n    xs, ys = extract_xy(row, part, N_POINTS[part])\n    mask = np.isfinite(xs) & np.isfinite(ys)\n    if mask.any():\n        ax.scatter(xs[mask], ys[mask], c=color, s=12)\n    draw_connections_2d(ax, xs, ys, CONNS[part], color=color, lw=1)\n    ax.set_title(title)\n\ndef set_limits(ax, parts_subset):\n    xs_all, ys_all = [], []\n    for p in parts_subset:\n        if p not in N_POINTS: \n            continue\n        # muestreamos primeras 50 frames para bounds rápidos\n        upto = min(50, len(seq))\n        for i in range(upto):\n            xs, ys = extract_xy(seq.iloc[i], p, N_POINTS[p])\n            m = np.isfinite(xs) & np.isfinite(ys)\n            xs_all.extend(xs[m]); ys_all.extend(ys[m])\n    if xs_all and ys_all:\n        xmin, xmax = np.min(xs_all), np.max(xs_all)\n        ymin, ymax = np.min(ys_all), np.max(ys_all)\n        if xmin == xmax: xmin, xmax = 0, 1\n        if ymin == ymax: ymin, ymax = 0, 1\n        pad_x = 0.05 * (xmax - xmin); pad_y = 0.05 * (ymax - ymin)\n        ax.set_xlim(xmin - pad_x, xmax + pad_x)\n        ax.set_ylim(ymin - pad_y, ymax + pad_y)\n    else:\n        ax.set_xlim(0,1); ax.set_ylim(0,1)\n    ax.set_aspect('equal', adjustable='box')\n\n# -----------------------------\n# (E) Animación\n# -----------------------------\nFPS = 12\nINTERVAL_MS = int(1000 / FPS)\n\nfig, (ax_hand, ax_pose) = plt.subplots(1, 2, figsize=(12, 6))\nplt.tight_layout()\n\ndef update(frame_idx):\n    row = seq.iloc[frame_idx]\n    ax_hand.cla(); ax_pose.cla()\n\n    color = \"tab:red\" if HAND_TO_PLOT == \"right_hand\" else \"tab:blue\"\n    title = \"Right Hand\" if HAND_TO_PLOT == \"right_hand\" else \"Left Hand\"\n    plot_part_2d(ax_hand, row, HAND_TO_PLOT, color, title)\n    set_limits(ax_hand, (HAND_TO_PLOT,))\n\n    plot_part_2d(ax_pose, row, \"pose\", \"tab:orange\", \"Pose\")\n    if DRAW_FACE:\n        plot_part_2d(ax_pose, row, \"face\", \"tab:green\", \"Face\")\n        set_limits(ax_pose, (\"pose\", \"face\"))\n    else:\n        set_limits(ax_pose, (\"pose\",))\n    ax_pose.invert_yaxis()  # importante para que hombros queden arriba (sistema imagen)\n    fig.suptitle(f\"Seq {SEQ_ID} · Frame {frame_idx+1}/{len(seq)}\", fontsize=14)\n\nanim = FuncAnimation(fig, update, frames=len(seq), interval=INTERVAL_MS)\n\nOUTPUT_GIF = \"asl_2d.gif\"\nanim.save(OUTPUT_GIF, writer=PillowWriter(fps=FPS))\nplt.close()\nprint(f\"GIF 2D guardado: {OUTPUT_GIF}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T16:14:19.336944Z","iopub.execute_input":"2025-09-09T16:14:19.337356Z","iopub.status.idle":"2025-09-09T16:15:24.204564Z","shell.execute_reply.started":"2025-09-09T16:14:19.337325Z","shell.execute_reply":"2025-09-09T16:15:24.203315Z"}},"outputs":[{"name":"stdout","text":"Usando SEQ_ID = 1975433633 con 127 frames\nHand seleccionada (2D): right_hand\nGIF 2D guardado: asl_2d.gif\n","output_type":"stream"}],"execution_count":11}]}